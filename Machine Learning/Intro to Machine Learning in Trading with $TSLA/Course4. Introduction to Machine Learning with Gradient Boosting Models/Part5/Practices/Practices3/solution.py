# import pandas as pd
# from sklearn.preprocessing import StandardScaler
# from sklearn.model_selection import train_test_split
# from sklearn.ensemble import GradientBoostingRegressor
# from sklearn.metrics import mean_squared_error
# import matplotlib.pyplot as plt
# import datasets

# # Load TSLA dataset
# tesla = datasets.load_dataset('codesignal/tsla-historic-prices')
# tesla_df = pd.DataFrame(tesla['train'])

# # Convert Date column to datetime type
# tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])

# # TODO: Create new features: Previous Close, Day Percentage Change, High-Low Spread, Close-Prev Close Ratio
# # Previous Close: The adjusted closing price of the previous day.
# # Day Percentage Change: The percentage change in the adjusted closing price from the previous day to the current day.
# # High-Low Spread: The difference between the high and low prices of the day.
# # Close-Prev Close Ratio: The ratio of the adjusted closing price to the previous day's adjusted closing price.

# tesla_df.dropna(inplace=True)

# # TODO: Select features and the target
# # The target will be the 'Day_Pct_Change' column

# # TODO: Standardize the features

# # TODO: Split the data into training and testing sets

# # TODO: Instantiate the Gradient Boosting model with early stopping

# # TODO: Fit the model

# # TODO: Make predictions and evaluate the model using Mean Squared Error (MSE)

# # TODO: Visualize predictions vs. actual values

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import datasets

# Suppress any potential warnings for cleaner output
import warnings
warnings.filterwarnings("ignore")

# Load TSLA dataset
tesla = datasets.load_dataset('codesignal/tsla-historic-prices')
tesla_df = pd.DataFrame(tesla['train'])

# Convert Date column to datetime type
tesla_df['Date'] = pd.to_datetime(tesla_df['Date'])

# Create new features
# Previous Close: The adjusted closing price of the previous day.
tesla_df['Previous_Close'] = tesla_df['Adj Close'].shift(1)

# Day Percentage Change: The percentage change in the adjusted closing price from the previous day to the current day.
tesla_df['Day_Pct_Change'] = ((tesla_df['Adj Close'] - tesla_df['Previous_Close']) / tesla_df['Previous_Close']) * 100

# High-Low Spread: The difference between the high and low prices of the day.
tesla_df['High_Low_Spread'] = tesla_df['High'] - tesla_df['Low']

# Close-Prev Close Ratio: The ratio of the adjusted closing price to the previous day's adjusted closing price.
tesla_df['Close_Prev_Close_Ratio'] = tesla_df['Adj Close'] / tesla_df['Previous_Close']

# Drop NaN values generated by the indicators
tesla_df.dropna(inplace=True)

# Select features and the target
# The target is the 'Day_Pct_Change' column
feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume',
                   'Previous_Close', 'High_Low_Spread', 'Close_Prev_Close_Ratio']
features = tesla_df[feature_columns].values
target = tesla_df['Day_Pct_Change'].values

# Split the data into training and testing sets
# Using 75% for training and 25% for testing
X_train, X_test, y_train, y_test = train_test_split(
    features, target, test_size=0.25, random_state=42
)

# Standardize the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Instantiate the Gradient Boosting model with early stopping
gb_model_early_stop = GradientBoostingRegressor(
    n_estimators=1000,           # Maximum number of trees
    learning_rate=0.05,          # Learning rate shrinks the contribution of each tree
    max_depth=3,                 # Depth of the individual regression estimators
    min_samples_split=2,         # Minimum number of samples required to split an internal node
    min_samples_leaf=1,          # Minimum number of samples required to be at a leaf node
    random_state=42,             # Seed for reproducibility
    n_iter_no_change=10,         # Early stopping after 10 iterations with no improvement
    validation_fraction=0.1,     # 10% of training data used for validation
    tol=1e-4                     # Tolerance for the early stopping
)

# Fit the model with early stopping
gb_model_early_stop.fit(X_train_scaled, y_train)

# Instantiate the Gradient Boosting model without early stopping
gb_model_no_early_stop = GradientBoostingRegressor(
    n_estimators=1000,
    learning_rate=0.05,
    max_depth=3,
    min_samples_split=2,
    min_samples_leaf=1,
    random_state=42
)

# Fit the model without early stopping
gb_model_no_early_stop.fit(X_train_scaled, y_train)

# Make predictions on the test set
y_pred_early_stop = gb_model_early_stop.predict(X_test_scaled)
y_pred_no_early_stop = gb_model_no_early_stop.predict(X_test_scaled)

# Evaluate the models using Mean Squared Error (MSE)
mse_early_stop = mean_squared_error(y_test, y_pred_early_stop)
mse_no_early_stop = mean_squared_error(y_test, y_pred_no_early_stop)

print(f"Mean Squared Error with Early Stopping: {mse_early_stop:.4f}")
print(f"Mean Squared Error without Early Stopping: {mse_no_early_stop:.4f}")

# Visualize predictions vs. actual values for the model with early stopping
plt.figure(figsize=(14, 6))

# Subplot 1: Early Stopping
plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred_early_stop, alpha=0.5, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title('Early Stopping Model: Actual vs. Predicted')
plt.xlabel('Actual Day Percentage Change')
plt.ylabel('Predicted Day Percentage Change')

# Subplot 2: No Early Stopping
plt.subplot(1, 2, 2)
plt.scatter(y_test, y_pred_no_early_stop, alpha=0.5, color='green')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title('No Early Stopping Model: Actual vs. Predicted')
plt.xlabel('Actual Day Percentage Change')
plt.ylabel('Predicted Day Percentage Change')

plt.tight_layout()
plt.show()

# Compute and visualize feature importance for the model with early stopping
feature_importance = gb_model_early_stop.feature_importances_
feature_importance_df = pd.DataFrame({
    'Feature': feature_columns,
    'Importance': feature_importance
}).sort_values(by='Importance', ascending=False)

print("\nFeature Importance (with Early Stopping):\n", feature_importance_df)

# Plotting feature importance
plt.figure(figsize=(10, 6))
plt.bar(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')
plt.title('Feature Importances (Early Stopping Model)')
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
