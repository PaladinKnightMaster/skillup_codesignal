# Running Neural Network Layers in PyTorch

You've succeeded so far in learning about PyTorch's Linear Layers and different Activation Functions! Let's put that knowledge into practice by running some provided Python code.

The code creates and processes a `tensor` through a layer of the neural network. It uses the `ReLU` and `Sigmoid` activation functions to introduce non-linearity into the tensor transformation. Run this code carefully to consolidate your understanding and observe the outputs and the effects of both activation functions.

Note: Before running, give us a moment to install PyTorch in the environment. We're setting up everything for your practice! üõ†Ô∏èüî•