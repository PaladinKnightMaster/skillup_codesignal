# Mastering Dropout and Regularization in PyTorch

Congratulations on mastering dropout and L2 regularization to avoid overfitting! Now we'll put these skills to the test by implementing dropout and L2 regularization with weight decay in a PyTorch model.

Your task is to create a neural network, define dropout layers, set up the loss function, and configure the optimizer with weight decay. Then, train the model for a fixed number of epochs, printing the loss every ten epochs.